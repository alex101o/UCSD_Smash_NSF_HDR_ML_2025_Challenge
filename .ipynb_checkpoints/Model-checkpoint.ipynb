{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "670b869b-74d9-4797-97f7-01a3ec997917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "from argparse import ArgumentParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1991d2d-31c7-4376-a485-b9a7ea0abdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_args(argv=None):\n",
    "    p = ArgumentParser()\n",
    "\n",
    "    # paths\n",
    "    p.add_argument(\"--train_csv\", type=str, default=\"hackdata/sentinel-beetles/public_release/train.csv\")\n",
    "    p.add_argument(\"--val_csv\", type=str, default=\"hackdata/sentinel-beetles/public_release/val.csv\")\n",
    "    p.add_argument(\"--train_img_dir\", type=str, default=\"training_images\")\n",
    "    p.add_argument(\"--val_img_dir\", type=str, default=\"validation_images\")\n",
    "    p.add_argument(\"--save_dir\", type=str, default=\"ckpts\")\n",
    "\n",
    "    # columns\n",
    "    p.add_argument(\"--event_col\", type=str, default=\"eventID\")\n",
    "    p.add_argument(\"--img_col\", type=str, default=\"relative_img_loc\")\n",
    "\n",
    "    # targets\n",
    "    p.add_argument(\"--spei30_col\", type=str, default=\"SPEI_30d\")\n",
    "    p.add_argument(\"--spei1y_col\", type=str, default=\"SPEI_1y\")\n",
    "    p.add_argument(\"--spei2y_col\", type=str, default=\"SPEI_2y\")\n",
    "\n",
    "    # model / data\n",
    "    p.add_argument(\"--img_size\", type=int, default=512)\n",
    "    p.add_argument(\"--k_max\", type=int, default=8)          # max images per event used\n",
    "    p.add_argument(\"--batch_size\", type=int, default=1)     # events per batch (keep small!)\n",
    "    p.add_argument(\"--num_workers\", type=int, default=1)\n",
    "    p.add_argument(\"--seed\", type=int, default=0)\n",
    "\n",
    "    # optimization\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--lr\", type=float, default=3e-5)        # good default for finetuning convnext_small\n",
    "    p.add_argument(\"--weight_decay\", type=float, default=0.05)\n",
    "    p.add_argument(\"--grad_accum\", type=int, default=1)     # increase if OOM\n",
    "    p.add_argument(\"--freeze_backbone_epochs\", type=int, default=1)  # stabilize early training\n",
    "\n",
    "    return p.parse_args(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "105fe99b-1acb-42b0-ab76-a9e4535dab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score_np(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    ss_res = float(((y_true - y_pred) ** 2).sum())\n",
    "    ss_tot = float(((y_true - y_true.mean()) ** 2).sum())\n",
    "    if ss_tot == 0.0:\n",
    "        return 0.0\n",
    "    return 1.0 - ss_res / ss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2c36e504-18bd-4a93-8d0b-cb2bbce2795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_spei_r2(gts: np.ndarray, preds: np.ndarray) -> Tuple[float, float, float]:\n",
    "    return (\n",
    "        r2_score_np(gts[:, 0], preds[:, 0]),\n",
    "        r2_score_np(gts[:, 1], preds[:, 1]),\n",
    "        r2_score_np(gts[:, 2], preds[:, 2]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "21cfba4e-a757-4d35-91d3-f6893b8f8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each __getitem__ returns:\n",
    "      x: (K, 3, H, W) tensor of beetle images for this event (padded if <K)\n",
    "      mask: (K,) float mask where 1 = real image, 0 = padding\n",
    "      y: (3,) float targets for the event\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path: str, img_dir: str, event_col: str, img_col: str, target_cols: Tuple[str, str, str], tfm, k_max: int, train_mode: bool, seed: int = 0,):\n",
    "        self.df = pd.read_csv(csv_path).reset_index(drop=True)\n",
    "        self.img_root = Path(img_dir)\n",
    "        self.event_col = event_col\n",
    "        self.img_col = img_col\n",
    "        self.target_cols = target_cols\n",
    "        self.tfm = tfm\n",
    "        self.k_max = k_max\n",
    "        self.train_mode = train_mode\n",
    "        self.rng = random.Random(seed)\n",
    "\n",
    "        # sanity columns\n",
    "        for col in [event_col, img_col, *target_cols]:\n",
    "            if col not in self.df.columns:\n",
    "                raise KeyError(f\"Missing column '{col}' in {csv_path}. Columns: {list(self.df.columns)}\")\n",
    "\n",
    "        # drop missing\n",
    "        self.df = self.df.dropna(subset=[event_col, img_col, *target_cols]).reset_index(drop=True)\n",
    "\n",
    "        \n",
    "        # Build event -> row indices\n",
    "        self.event_to_rows: Dict[str, List[int]] = {}\n",
    "        for i in range(len(self.df)):\n",
    "            ev = str(self.df.loc[i, self.event_col])\n",
    "            self.event_to_rows.setdefault(ev, []).append(i)\n",
    "        self.events = list(self.event_to_rows.keys())\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.events)\n",
    "\n",
    "    def _open_image(self, rel: str) -> Image.Image:\n",
    "        rel = str(rel).lstrip(\"/\").replace(\"\\\\\", \"/\")\n",
    "        p = self.img_root / rel\n",
    "        if not p.exists():\n",
    "            # fallback: basename only\n",
    "            p2 = self.img_root / Path(rel).name\n",
    "            if p2.exists():\n",
    "                p = p2\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Image not found: {p} (also tried {p2})\")\n",
    "        return Image.open(p).convert(\"RGB\")\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        ev = self.events[idx]\n",
    "        rows = self.event_to_rows[ev]\n",
    "\n",
    "        # targets from first row\n",
    "        row0 = self.df.loc[rows[0]]\n",
    "        y = torch.tensor([row0[c] for c in self.target_cols], dtype=torch.float32)\n",
    "\n",
    "        \n",
    "        # sample up to K specimens for this event\n",
    "        if self.train_mode and len(rows) > self.k_max:\n",
    "            chosen = self.rng.sample(rows, self.k_max)\n",
    "        else:\n",
    "            # deterministic for validation\n",
    "            chosen = rows[: self.k_max]\n",
    "\n",
    "        # load + transform images\n",
    "        xs: List[torch.Tensor] = []\n",
    "        for r in chosen:\n",
    "            rel_path = self.df.loc[r, self.img_col]\n",
    "            xs.append(self.tfm(self._open_image(rel_path)))\n",
    "\n",
    "        n = len(xs)\n",
    "        H = W = self.tfm._img_size\n",
    "        \n",
    "        # pad to K\n",
    "        if n < self.k_max:\n",
    "            pad = torch.zeros((self.k_max - n, 3, H, W), dtype=torch.float32)\n",
    "            x = torch.cat([torch.stack(xs, dim=0), pad], dim=0) if n > 0 else pad\n",
    "            mask = torch.cat([torch.ones(n), torch.zeros(self.k_max - n)]).float()\n",
    "        else:\n",
    "            x = torch.stack(xs[: self.k_max], dim=0)\n",
    "            mask = torch.ones(self.k_max).float()\n",
    "\n",
    "        return x, mask, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "539d9d18-31d2-4c15-a3a0-3f27e82faaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventConvNeXtRegressor(nn.Module):\n",
    "    def __init__(self, backbone_name: str = \"convnext_small\"):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\"convnext_small\", pretrained=True, num_classes=0, cache_dir=str(Path(\"timm_cache\").resolve()),\n",
    ")\n",
    "        d = self.backbone.num_features\n",
    "        self.head = nn.Linear(d, 6)  # 3 mu + 3 log_sigma\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: (B, K, 3, H, W)\n",
    "        mask: (B, K) 1 for real, 0 for padded\n",
    "        \"\"\"\n",
    "        B, K, C, H, W = x.shape\n",
    "        feats = self.backbone(x.view(B * K, C, H, W))  # (B*K, d)\n",
    "        d = feats.shape[-1]\n",
    "        feats = feats.view(B, K, d)             # (B, K, d)\n",
    "\n",
    "        # masked mean pool\n",
    "        m = mask.unsqueeze(-1)                  # (B, K, 1)\n",
    "        denom = m.sum(dim=1).clamp_min(1.0)     # (B, 1)\n",
    "        event_feat = (feats * m).sum(dim=1) / denom  # (B, d)\n",
    "\n",
    "        out = self.head(event_feat)             # (B, 6)\n",
    "        mu = out[:, :3]                         # (B, 3)\n",
    "        sigma = F.softplus(out[:, 3:]) + 1e-6\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "096ed461-7f6e-4657-a8a3-b63e29c2608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_nll(y: torch.Tensor, mu: torch.Tensor, sigma: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    y, mu, sigma: (B, 3)\n",
    "    Negative log-likelihood for independent Gaussian dims.\n",
    "    \"\"\"\n",
    "    # 0.5*((y-mu)/sigma)^2 + log(sigma)\n",
    "    return (0.5 * ((y - mu) / sigma).pow(2) + torch.log(sigma)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "377dc767-69a9-4321-9126-91a317bc1607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    args = get_training_args(argv)\n",
    "\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize((args.img_size, args.img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                             std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    tfm._img_size = args.img_size\n",
    "\n",
    "    target_cols = (args.spei30_col, args.spei1y_col, args.spei2y_col)\n",
    "\n",
    "    train_ds = EventDataset(\n",
    "        csv_path=args.train_csv,\n",
    "        img_dir=args.train_img_dir,\n",
    "        event_col=args.event_col,\n",
    "        img_col=args.img_col,\n",
    "        target_cols=target_cols,\n",
    "        tfm=tfm,\n",
    "        k_max=args.k_max,\n",
    "        train_mode=True,\n",
    "        seed=args.seed,\n",
    "    )\n",
    "    val_ds = EventDataset(\n",
    "        csv_path=args.val_csv,\n",
    "        img_dir=args.val_img_dir,\n",
    "        event_col=args.event_col,\n",
    "        img_col=args.img_col,\n",
    "        target_cols=target_cols,\n",
    "        tfm=tfm,\n",
    "        k_max=args.k_max,\n",
    "        train_mode=False,\n",
    "        seed=args.seed,\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = EventConvNeXtRegressor(\"convnext_small\").to(device)\n",
    "\n",
    "    def set_backbone_trainable(trainable: bool):\n",
    "        for p in model.backbone.parameters():\n",
    "            p.requires_grad = trainable\n",
    "            \n",
    "    # freeze backbone initially (optional but recommended for stability)\n",
    "    if args.freeze_backbone_epochs > 0:\n",
    "        set_backbone_trainable(False)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=(1e-3 if args.freeze_backbone_epochs > 0 else args.lr),\n",
    "        weight_decay=args.weight_decay\n",
    "    )\n",
    "\n",
    "    use_cuda = (device.type == \"cuda\")\n",
    "    scaler = torch.amp.GradScaler(\"cuda\", enabled=use_cuda)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=args.num_workers, pin_memory=(device.type == \"cuda\")\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.num_workers, pin_memory=(device.type == \"cuda\")\n",
    "    )\n",
    "    \n",
    "    save_dir = Path(args.save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    best_path = save_dir / \"event_convnext_small_best.pth\"\n",
    "\n",
    "    best_avg = -1.0\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        if epoch == args.freeze_backbone_epochs and args.freeze_backbone_epochs > 0:\n",
    "            set_backbone_trainable(True)\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "        # ---- train ----\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "        tr_preds, tr_gts = [], []\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"train {epoch}\", leave=False)\n",
    "        for step, (x, mask, y) in enumerate(pbar):\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            mask = mask.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\", enabled=use_cuda):\n",
    "\n",
    "                mu, sigma = model(x, mask)\n",
    "                loss = gaussian_nll(y, mu, sigma) / args.grad_accum\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (step + 1) % args.grad_accum == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            tr_loss += float(loss.item()) * args.grad_accum\n",
    "            tr_preds.append(mu.detach().cpu().numpy())\n",
    "            tr_gts.append(y.detach().cpu().numpy())\n",
    "            pbar.set_postfix({\"loss\": tr_loss / max(1, step + 1)})\n",
    "\n",
    "        tr_preds = np.concatenate(tr_preds, axis=0)\n",
    "        tr_gts = np.concatenate(tr_gts, axis=0)\n",
    "        tr30, tr1y, tr2y = evaluate_spei_r2(tr_gts, tr_preds)\n",
    "\n",
    "        # ---- val ----\n",
    "        model.eval()\n",
    "        va_loss = 0.0\n",
    "        va_preds, va_gts = [], []\n",
    "        pbar = tqdm(val_loader, desc=f\"val {epoch}\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for step, (x, mask, y) in enumerate(pbar):\n",
    "                x = x.to(device, non_blocking=True)\n",
    "                mask = mask.to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "\n",
    "                with torch.amp.autocast(\"cuda\", enabled=use_cuda):\n",
    "\n",
    "                    mu, sigma = model(x, mask)\n",
    "                    loss = gaussian_nll(y, mu, sigma)\n",
    "\n",
    "                va_loss += float(loss.item())\n",
    "                va_preds.append(mu.detach().cpu().numpy())\n",
    "                va_gts.append(y.detach().cpu().numpy())\n",
    "                pbar.set_postfix({\"loss\": va_loss / max(1, step + 1)})\n",
    "\n",
    "        va_preds = np.concatenate(va_preds, axis=0)\n",
    "        va_gts = np.concatenate(va_gts, axis=0)\n",
    "        v30, v1y, v2y = evaluate_spei_r2(va_gts, va_preds)\n",
    "        avg = (v30 + v1y + v2y) / 3.0\n",
    "        print(\n",
    "            f\"epoch {epoch:03d} | \"\n",
    "            f\"train_loss={tr_loss/len(train_loader):.4f} val_loss={va_loss/len(val_loader):.4f} | \"\n",
    "            f\"train_r2=({tr30:.3f},{tr1y:.3f},{tr2y:.3f}) \"\n",
    "            f\"val_r2=({v30:.3f},{v1y:.3f},{v2y:.3f}) avg={avg:.3f} | \"\n",
    "            f\"best_avg={best_avg:.3f} @ {best_epoch}\"\n",
    "        )\n",
    "\n",
    "        if avg > best_avg:\n",
    "            best_avg = avg\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "\n",
    "    print(\"Saved best weights to:\", best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ae6ee-0dc1-4af8-9874-7a13f631feb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738110dea82e4d80aff9d5584632d8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/201M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 0:   0%|          | 4/1088 [01:07<4:56:09, 16.39s/it, loss=1.64]"
     ]
    }
   ],
   "source": [
    "main([\n",
    "  \"--train_img_dir\",\"training_images\",\n",
    "  \"--val_img_dir\",\"validation_images\",\n",
    "  \"--event_col\",\"eventID\",\n",
    "  \"--img_col\",\"relative_img_loc\",\n",
    "  \"--spei30_col\",\"SPEI_30d\",\n",
    "  \"--spei1y_col\",\"SPEI_1y\",\n",
    "  \"--spei2y_col\",\"SPEI_2y\",\n",
    "  \"--batch_size\",\"1\",\n",
    "  \"--k_max\",\"8\",\n",
    "  \"--epochs\",\"5\",\n",
    "  \"--lr\",\"3e-5\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3a3023c-7721-442f-b04a-a9c24712b3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c781ad6-0e34-4472-9c7c-ab957b88a9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "670b869b-74d9-4797-97f7-01a3ec997917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as TF\n",
    "import torch\n",
    "import torchvision.io as io\n",
    "import math\n",
    "\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "from argparse import ArgumentParser\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f1991d2d-31c7-4376-a485-b9a7ea0abdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_args(argv=None):\n",
    "    p = ArgumentParser()\n",
    "\n",
    "    # paths\n",
    "    p.add_argument(\"--train_csv\", type=str, default=\"hackdata/sentinel-beetles/public_release/train.csv\")\n",
    "    p.add_argument(\"--val_csv\", type=str, default=\"hackdata/sentinel-beetles/public_release/val.csv\")\n",
    "    p.add_argument(\"--train_img_dir\", type=str, default=\"training_images\")\n",
    "    p.add_argument(\"--mask_train_img_dir\", type=str, default=\"masked_training_images\")\n",
    "    p.add_argument(\"--train_color_dir\", type=str, default=\"hackdata/sentinel-beetles/color_and_scale_images\")\n",
    "\n",
    "\n",
    "\n",
    "    p.add_argument(\"--val_img_dir\", type=str, default=\"validation_images\")\n",
    "    p.add_argument(\"--mask_val_img_dir\", type=str, default=\"masked_validation_images\")\n",
    "    p.add_argument(\"--val_color_dir\", type=str, default=\"hackdata/sentinel-beetles/color_and_scale_images\")\n",
    "    p.add_argument(\"--save_dir\", type=str, default=\"ckpts\")\n",
    "\n",
    "    # columns\n",
    "    p.add_argument(\"--event_col\", type=str, default=\"eventID\")\n",
    "    p.add_argument(\"--img_col\", type=str, default=\"relative_img_loc\")\n",
    "    p.add_argument(\"--color_col\", type=str, default=\"colorpicker_path\")\n",
    "\n",
    "    # targets\n",
    "    p.add_argument(\"--spei30_col\", type=str, default=\"SPEI_30d\")\n",
    "    p.add_argument(\"--spei1y_col\", type=str, default=\"SPEI_1y\")\n",
    "    p.add_argument(\"--spei2y_col\", type=str, default=\"SPEI_2y\")\n",
    "\n",
    "    # model / data\n",
    "    p.add_argument(\"--img_size\", type=int, default=224)\n",
    "    p.add_argument(\"--k_max\", type=int, default=8)          # max images per event used\n",
    "    p.add_argument(\"--batch_size\", type=int, default=1)     # events per batch (keep small!)\n",
    "    p.add_argument(\"--num_workers\", type=int, default=1)\n",
    "    p.add_argument(\"--seed\", type=int, default=0)\n",
    "\n",
    "    # optimization\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--lr\", type=float, default=3e-5)        # good default for finetuning convnext_small\n",
    "    p.add_argument(\"--weight_decay\", type=float, default=0.05)\n",
    "    p.add_argument(\"--grad_accum\", type=int, default=1)     # increase if OOM\n",
    "    p.add_argument(\"--freeze_backbone_epochs\", type=int, default=1)  # stabilize early training\n",
    "\n",
    "    return p.parse_args(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "105fe99b-1acb-42b0-ab76-a9e4535dab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score_np(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    ss_res = float(((y_true - y_pred) ** 2).sum())\n",
    "    ss_tot = float(((y_true - y_true.mean()) ** 2).sum())\n",
    "    if ss_tot == 0.0:\n",
    "        return 0.0\n",
    "    return 1.0 - ss_res / ss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2c36e504-18bd-4a93-8d0b-cb2bbce2795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_spei_r2(gts: np.ndarray, preds: np.ndarray) -> Tuple[float, float, float]:\n",
    "    return (\n",
    "        r2_score_np(gts[:, 0], preds[:, 0]),\n",
    "        r2_score_np(gts[:, 1], preds[:, 1]),\n",
    "        r2_score_np(gts[:, 2], preds[:, 2]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "79eb4142-d730-4eaa-a868-f214b822d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotate90:\n",
    "    def __init__(self, angles=(0, 90, 180, 270), p=1.0):\n",
    "        self.angles = angles\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > self.p:\n",
    "            return img\n",
    "        angle = random.choice(self.angles)\n",
    "        return TF.rotate(img, angle, expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d20d3a8d-3a29-4e14-94c7-22e465dadf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normalization_factors(color_img_rgb):\n",
    "    \"\"\"\n",
    "    Calculates normalization factors based on the extreme pixels in an image.\n",
    "    Input: img_rgb (Tensor) of shape [3, H, W] normalized to [0, 1]\n",
    "    Output: (brightness_factor, gamma, hue_factor, saturation_factor)\n",
    "    \"\"\"\n",
    "    # 1. Convert to HSV\n",
    "    rgb = np.array(color_img_rgb.convert(\"RGB\")) # (3,H,W) in [0,1]\n",
    "    hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV).astype(np.float32)               # true HSV in [0,1]\n",
    "    h = hsv[..., 0] / 179.0\n",
    "    s = hsv[..., 1] / 255.0\n",
    "    v = hsv[..., 2] / 255.0\n",
    "\n",
    "    h_f = torch.from_numpy(h).flatten()\n",
    "    s_f = torch.from_numpy(s).flatten()\n",
    "    v_f = torch.from_numpy(v).flatten()\n",
    "\n",
    "    # --- IDENTIFY PIXELS ---\n",
    "    v_black = v_f.min().item()\n",
    "\n",
    "    low_sat = s_f < 0.2\n",
    "    v_white = v_f[low_sat].max().item() if low_sat.any() else v_f.max().item()\n",
    "\n",
    "    if low_sat.any():\n",
    "        vv = v_f[low_sat]\n",
    "        gray_scores = (vv - 0.5).abs()\n",
    "        v_gray = vv[gray_scores.argmin()].item()\n",
    "    else:\n",
    "        v_gray = v_f[(v_f - 0.5).abs().argmin()].item()\n",
    "\n",
    "    sat_mask = s_f > 0.2\n",
    "    if sat_mask.any():\n",
    "        hh = h_f[sat_mask]\n",
    "        ss = s_f[sat_mask]\n",
    "        vv = v_f[sat_mask]\n",
    "        dist_to_red = torch.minimum((hh - 0.0).abs(), (hh - 1.0).abs())\n",
    "        score = (ss + vv) - dist_to_red\n",
    "        idx = score.argmax()\n",
    "        h_red = hh[idx].item()\n",
    "        s_red = ss[idx].item()\n",
    "    else:\n",
    "        h_red, s_red = 0.0, 1.0\n",
    "\n",
    "    # --- FACTORS ---\n",
    "    brightness = 1.0 / v_white if v_white > 1e-6 else 1.0\n",
    "    contrast = 1.0 / ((v_white - v_black) + 1e-6)\n",
    "\n",
    "    vg = max(1e-6, min(0.999999, v_gray * brightness))\n",
    "    gamma = math.log(0.5) / math.log(vg) if vg not in (0.0, 1.0) else 1.0\n",
    "\n",
    "    hue_shift = -h_red\n",
    "    if hue_shift < -0.5: hue_shift += 1.0\n",
    "    if hue_shift >  0.5: hue_shift -= 1.0\n",
    "\n",
    "    sat_scale = 1.0 / s_red if s_red > 1e-6 else 1.0\n",
    "\n",
    "    return hue_shift, sat_scale, contrast, gamma, brightness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "db01a500-4bc9-458b-bbe2-855888e6c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingParamTfm:\n",
    "    def __init__(self, img_size: int = 224):\n",
    "        self._img_size = img_size\n",
    "        self.post = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),      # mirror (left-right)\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                 std=(0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img, color, color_dir):\n",
    "        image = Image.open(color_dir/Path(color)).convert(\"RGB\")\n",
    "        hue_shift, sat_scale, contrast, gamma, brightness = calculate_normalization_factors(image)\n",
    "        hue_shift = float(max(-0.5, min(0.5, hue_shift)))\n",
    "        sat_scale = float(max(0.1, min(3.0, sat_scale)))\n",
    "        contrast  = float(max(0.1, min(3.0, contrast)))\n",
    "        brightness= float(max(0.1, min(3.0, brightness)))\n",
    "        gamma     = float(max(0.1, min(3.0, gamma)))\n",
    "        img = TF.adjust_hue(img, hue_shift)\n",
    "        img = TF.adjust_saturation(img, sat_scale)\n",
    "        img = TF.adjust_contrast(img, contrast)\n",
    "        img = TF.adjust_gamma(img, gamma=gamma, gain=1.0)\n",
    "        img = TF.adjust_brightness(img, brightness)\n",
    "        return self.post(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "65244c7e-f553-495c-92f3-9c749861b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationParamTfm:\n",
    "    def __init__(self, img_size: int = 224):\n",
    "        self._img_size = img_size\n",
    "        self.post = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                 std=(0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img, color, color_dir):\n",
    "        return self.post(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "21cfba4e-a757-4d35-91d3-f6893b8f8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each __getitem__ returns:\n",
    "      x: (K, 3, H, W) tensor of beetle images for this event (padded if <K)\n",
    "      mask: (K,) float mask where 1 = real image, 0 = padding\n",
    "      y: (3,) float targets for the event\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path: str, masked_img_dir: str, img_dir: str, color_dir: str, event_col: str, img_col: str, color_col: str, target_cols: Tuple[str, str, str], tfm, k_max: int, train_mode: bool, seed: int = 0,):\n",
    "        self.df = pd.read_csv(csv_path).reset_index(drop=True)\n",
    "        self.img_root = Path(masked_img_dir)\n",
    "        self.raw_img_root = Path(img_dir)\n",
    "        self.color_dir = Path(color_dir)\n",
    "        self.event_col = event_col\n",
    "        self.img_col = img_col\n",
    "        self.color_col = color_col\n",
    "        self.target_cols = target_cols\n",
    "        self.tfm = tfm\n",
    "        self.k_max = k_max\n",
    "        self.train_mode = train_mode\n",
    "        self.rng = random.Random(seed)\n",
    "\n",
    "        # sanity columns\n",
    "        for col in [event_col, img_col, *target_cols]:\n",
    "            if col not in self.df.columns:\n",
    "                raise KeyError(f\"Missing column '{col}' in {csv_path}. Columns: {list(self.df.columns)}\")\n",
    "\n",
    "        # drop missing\n",
    "        self.df = self.df.dropna(subset=[event_col, img_col, *target_cols]).reset_index(drop=True)\n",
    "\n",
    "        \n",
    "        # Build event -> row indices\n",
    "        self.event_to_rows: Dict[str, List[int]] = {}\n",
    "        for i in range(len(self.df)):\n",
    "            ev = str(self.df.loc[i, self.event_col])\n",
    "            self.event_to_rows.setdefault(ev, []).append(i)\n",
    "        self.events = list(self.event_to_rows.keys())\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.events)\n",
    "\n",
    "    def _open_image(self, rel: str) -> Image.Image:\n",
    "        rel = str(rel).lstrip(\"/\").replace(\"\\\\\", \"/\")\n",
    "        p = self.img_root / rel\n",
    "        if not p.exists():\n",
    "            # fallback: basename only\n",
    "            p = self.img_root / Path(rel).name\n",
    "            if not p.exists():\n",
    "                p = self.raw_img_root / rel\n",
    "                if not p.exists():\n",
    "                    p = self.raw_img_root / Path(rel).name\n",
    "                    if not p.exists():\n",
    "                        raise FileNotFoundError(f\"Image not found: {p}\")\n",
    "        return Image.open(p).convert(\"RGB\")\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        ev = self.events[idx]\n",
    "        rows = self.event_to_rows[ev]\n",
    "\n",
    "        # targets from first row\n",
    "        row0 = self.df.loc[rows[0]]\n",
    "        y = torch.tensor([row0[c] for c in self.target_cols], dtype=torch.float32)\n",
    "\n",
    "        \n",
    "        # sample up to K specimens for this event\n",
    "        if self.train_mode and len(rows) > self.k_max:\n",
    "            chosen = self.rng.sample(rows, self.k_max)\n",
    "        else:\n",
    "            # deterministic for validation\n",
    "            chosen = rows[: self.k_max]\n",
    "\n",
    "        # load + transform images\n",
    "        xs: List[torch.Tensor] = []\n",
    "        for r in chosen:\n",
    "            rel_path = self.df.loc[r, self.img_col]\n",
    "            color_path = self.df.loc[r, self.color_col]\n",
    "            xs.append(self.tfm(self._open_image(rel_path), color_path, self.color_dir))\n",
    "\n",
    "        n = len(xs)\n",
    "        H = W = self.tfm._img_size\n",
    "        \n",
    "        # pad to K\n",
    "        if n < self.k_max:\n",
    "            pad = torch.zeros((self.k_max - n, 3, H, W), dtype=torch.float32)\n",
    "            x = torch.cat([torch.stack(xs, dim=0), pad], dim=0) if n > 0 else pad\n",
    "            mask = torch.cat([torch.ones(n), torch.zeros(self.k_max - n)]).float()\n",
    "        else:\n",
    "            x = torch.stack(xs[: self.k_max], dim=0)\n",
    "            mask = torch.ones(self.k_max).float()\n",
    "\n",
    "        return x, mask, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "539d9d18-31d2-4c15-a3a0-3f27e82faaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventConvNeXtRegressor(nn.Module):\n",
    "    def __init__(self, backbone_name: str = \"convnext_small\"):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\"convnext_small\", pretrained=True, num_classes=0, cache_dir=str(Path(\"timm_cache\").resolve()),\n",
    ")\n",
    "        d = self.backbone.num_features\n",
    "        self.head = nn.Linear(d, 6)  # 3 mu + 3 log_sigma\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: (B, K, 3, H, W)\n",
    "        mask: (B, K) 1 for real, 0 for padded\n",
    "        \"\"\"\n",
    "        B, K, C, H, W = x.shape\n",
    "        feats = self.backbone(x.view(B * K, C, H, W))  # (B*K, d)\n",
    "        d = feats.shape[-1]\n",
    "        feats = feats.view(B, K, d)             # (B, K, d)\n",
    "\n",
    "        # masked mean pool\n",
    "        m = mask.unsqueeze(-1)                  # (B, K, 1)\n",
    "        denom = m.sum(dim=1).clamp_min(1.0)     # (B, 1)\n",
    "        event_feat = (feats * m).sum(dim=1) / denom  # (B, d)\n",
    "\n",
    "        out = self.head(event_feat)             # (B, 6)\n",
    "        mu = out[:, :3]                         # (B, 3)\n",
    "        sigma = F.softplus(out[:, 3:]) + 1e-6\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "096ed461-7f6e-4657-a8a3-b63e29c2608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_nll(y: torch.Tensor, mu: torch.Tensor, sigma: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    y, mu, sigma: (B, 3)\n",
    "    Negative log-likelihood for independent Gaussian dims.\n",
    "    \"\"\"\n",
    "    # 0.5*((y-mu)/sigma)^2 + log(sigma)\n",
    "    return (0.5 * ((y - mu) / sigma).pow(2) + torch.log(sigma)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "377dc767-69a9-4321-9126-91a317bc1607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    args = get_training_args(argv)\n",
    "    img_size = args.img_size\n",
    "\n",
    "    train_tfm = TrainingParamTfm(img_size)\n",
    "    train_tfm._img_size = img_size  # keep your padding logic working\n",
    "\n",
    "    val_tfm = ValidationParamTfm(img_size)\n",
    "    val_tfm._img_size = img_size\n",
    "\n",
    "\n",
    "    target_cols = (args.spei30_col, args.spei1y_col, args.spei2y_col)\n",
    "\n",
    "    train_ds = EventDataset(\n",
    "        csv_path=args.train_csv,\n",
    "        masked_img_dir = args.mask_train_img_dir,\n",
    "        img_dir = args.train_img_dir,\n",
    "        color_dir = args.train_color_dir,\n",
    "        event_col=args.event_col,\n",
    "        img_col=args.img_col,\n",
    "        color_col=args.color_col,\n",
    "        target_cols=target_cols,\n",
    "        tfm=train_tfm,\n",
    "        k_max=args.k_max,\n",
    "        train_mode=True,\n",
    "        seed=args.seed,\n",
    "    )\n",
    "    val_ds = EventDataset(\n",
    "        csv_path=args.val_csv,\n",
    "        masked_img_dir = args.mask_val_img_dir,\n",
    "        img_dir = args.val_img_dir,\n",
    "        color_dir = args.val_color_dir,\n",
    "        event_col=args.event_col,\n",
    "        img_col=args.img_col,\n",
    "        color_col=args.color_col,\n",
    "        target_cols=target_cols,\n",
    "        tfm=val_tfm,\n",
    "        k_max=args.k_max,\n",
    "        train_mode=False,\n",
    "        seed=args.seed,\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = EventConvNeXtRegressor(\"convnext_small\").to(device)\n",
    "\n",
    "    def set_backbone_trainable(trainable: bool):\n",
    "        for p in model.backbone.parameters():\n",
    "            p.requires_grad = trainable\n",
    "            \n",
    "    # freeze backbone initially (optional but recommended for stability)\n",
    "    if args.freeze_backbone_epochs > 0:\n",
    "        set_backbone_trainable(False)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=(1e-3 if args.freeze_backbone_epochs > 0 else args.lr),\n",
    "        weight_decay=args.weight_decay\n",
    "    )\n",
    "\n",
    "    use_cuda = (device.type == \"cuda\")\n",
    "    scaler = torch.amp.GradScaler(\"cuda\", enabled=use_cuda)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=args.num_workers, pin_memory=(device.type == \"cuda\")\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.num_workers, pin_memory=(device.type == \"cuda\")\n",
    "    )\n",
    "    \n",
    "    save_dir = Path(args.save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    best_path = save_dir / \"event_convnext_small_mask_img_aug_best.pth\"\n",
    "\n",
    "    best_avg = -1.0\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        if epoch == args.freeze_backbone_epochs and args.freeze_backbone_epochs > 0:\n",
    "            set_backbone_trainable(True)\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "        # ---- train ----\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "        tr_preds, tr_gts = [], []\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"train {epoch}\", leave=False)\n",
    "        for step, (x, mask, y) in enumerate(pbar):\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            mask = mask.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.amp.autocast(\"cuda\", enabled=use_cuda):\n",
    "\n",
    "                mu, sigma = model(x, mask)\n",
    "                loss = gaussian_nll(y, mu, sigma) / args.grad_accum\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (step + 1) % args.grad_accum == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            tr_loss += float(loss.item()) * args.grad_accum\n",
    "            tr_preds.append(mu.detach().cpu().numpy())\n",
    "            tr_gts.append(y.detach().cpu().numpy())\n",
    "            pbar.set_postfix({\"loss\": tr_loss / max(1, step + 1)})\n",
    "\n",
    "        tr_preds = np.concatenate(tr_preds, axis=0)\n",
    "        tr_gts = np.concatenate(tr_gts, axis=0)\n",
    "        tr30, tr1y, tr2y = evaluate_spei_r2(tr_gts, tr_preds)\n",
    "\n",
    "        # ---- val ----\n",
    "        model.eval()\n",
    "        va_loss = 0.0\n",
    "        va_preds, va_gts = [], []\n",
    "        pbar = tqdm(val_loader, desc=f\"val {epoch}\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for step, (x, mask, y) in enumerate(pbar):\n",
    "                x = x.to(device, non_blocking=True)\n",
    "                mask = mask.to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "\n",
    "                with torch.amp.autocast(\"cuda\", enabled=use_cuda):\n",
    "\n",
    "                    mu, sigma = model(x, mask)\n",
    "                    loss = gaussian_nll(y, mu, sigma)\n",
    "\n",
    "                va_loss += float(loss.item())\n",
    "                va_preds.append(mu.detach().cpu().numpy())\n",
    "                va_gts.append(y.detach().cpu().numpy())\n",
    "                pbar.set_postfix({\"loss\": va_loss / max(1, step + 1)})\n",
    "\n",
    "        va_preds = np.concatenate(va_preds, axis=0)\n",
    "        va_gts = np.concatenate(va_gts, axis=0)\n",
    "        v30, v1y, v2y = evaluate_spei_r2(va_gts, va_preds)\n",
    "        avg = (v30 + v1y + v2y) / 3.0\n",
    "        print(\n",
    "            f\"epoch {epoch:03d} | \"\n",
    "            f\"train_loss={tr_loss/len(train_loader):.4f} val_loss={va_loss/len(val_loader):.4f} | \"\n",
    "            f\"train_r2=({tr30:.3f},{tr1y:.3f},{tr2y:.3f}) \"\n",
    "            f\"val_r2=({v30:.3f},{v1y:.3f},{v2y:.3f}) avg={avg:.3f} | \"\n",
    "            f\"best_avg={best_avg:.3f} @ {best_epoch}\"\n",
    "        )\n",
    "\n",
    "        if avg > best_avg:\n",
    "            best_avg = avg\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "\n",
    "    print(\"Saved best weights to:\", best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ae6ee-0dc1-4af8-9874-7a13f631feb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 0:  10%|â–ˆ         | 57/544 [01:51<13:06,  1.61s/it, loss=1.37]"
     ]
    }
   ],
   "source": [
    "main([\n",
    "  \"--train_img_dir\",\"training_images\",\n",
    "  \"--val_img_dir\",\"validation_images\",\n",
    "  \"--event_col\",\"eventID\",\n",
    "  \"--img_col\",\"relative_img_loc\",\n",
    "  \"--spei30_col\",\"SPEI_30d\",\n",
    "  \"--spei1y_col\",\"SPEI_1y\",\n",
    "  \"--spei2y_col\",\"SPEI_2y\",\n",
    "  \"--batch_size\",\"2\",\n",
    "  \"--k_max\",\"4\",\n",
    "  \"--epochs\",\"20\",\n",
    "  \"--lr\",\"3e-5\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a3023c-7721-442f-b04a-a9c24712b3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c781ad6-0e34-4472-9c7c-ab957b88a9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
